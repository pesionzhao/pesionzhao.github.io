
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../c9/">
      
      
        <link rel="next" href="../c11/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.2.7">
    
    
      
        <title>线程束基本函数与协作组 - ZPSXJTU</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.046329b4.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.85d0ee34.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans:300,300i,400,400i,700,700i%7CSource+Code+Pro:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans";--md-code-font:"Source Code Pro"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-8Q77YBREF9"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-8Q77YBREF9",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-8Q77YBREF9",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="Slate" data-md-color-primary="Blue-Grey" data-md-color-accent="red">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#simt-" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="ZPSXJTU" class="md-header__button md-logo" aria-label="ZPSXJTU" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 3 1 9l11 6 9-4.91V17h2V9M5 13.18v4L12 21l7-3.82v-4L12 17l-7-3.82Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ZPSXJTU
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              线程束基本函数与协作组
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Project/" class="md-tabs__link">
          
  
  经验之谈

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="md-tabs__link">
          
  
  论文笔记

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/" class="md-tabs__link">
          
  
  踩坑记录

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Learning/" class="md-tabs__link">
          
  
  学习文档

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../SeismicInversion/" class="md-tabs__link">
          
  
  地震反演

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  CUDA

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="ZPSXJTU" class="md-nav__button md-logo" aria-label="ZPSXJTU" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 3 1 9l11 6 9-4.91V17h2V9M5 13.18v4L12 21l7-3.82v-4L12 17l-7-3.82Z"/></svg>

    </a>
    ZPSXJTU
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    经验之谈
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            经验之谈
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Project/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    专栏介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Project/%E5%8D%95%E7%9B%B8%E6%9C%BA%E5%8F%8C%E5%85%89%E6%BA%90%E8%A7%86%E7%BA%BF%E4%BC%B0%E8%AE%A1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于单相机双光源的眼动交互
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Project/%E8%8D%A7%E5%85%89%E9%98%B5%E5%88%97%E7%9F%AB%E6%AD%A3%E8%AE%A1%E6%95%B0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    蛋白质荧光阵列矫正与计数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Project/JLU%20Captcha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    吉林大学教务管理系统验证码识别
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Project/robomaster%E5%B7%A5%E7%A8%8B%E7%9F%BF%E7%9F%B3%E8%AF%86%E5%88%AB/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    robomaster工程矿石识别
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Project/%E7%99%BE%E5%BA%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%AB%9E%E8%B5%9B%E5%88%92%E6%B0%B4%E8%AE%B0%E5%BD%95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    百度车载影像检测与分割
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Project/%E8%BF%90%E8%90%A5%E5%95%86%E6%A0%85%E6%A0%BC%E6%B4%BB%E8%B7%83%E5%BA%A6%E9%A2%84%E6%B5%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运营商栅格预测
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    论文笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            论文笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    专栏介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    网络解读
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            网络解读
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/Transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    屠榜的transformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%90%8A%E6%89%93%E4%B8%80%E5%88%87%E7%9A%84yolox/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    吊打一切的yoloX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/CascadeRCNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CascadeRCNN永远滴神
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/HR-Net%20%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    高分辨网络HR-Net
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%B0%8F%E7%9B%AE%E6%A0%87%E5%B0%81%E7%A5%9ETPH-YOLOV5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    小目标检测王者TPH-YOLOV5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/YOLOP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    嵌入式同时完成三大视觉任务YOLOP
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
        
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    理论基础
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            理论基础
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A3/Soft%20label/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从标签平滑和知识蒸馏看Soft Label
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    即插即用
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            即插即用
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%8D%B3%E6%8F%92%E5%8D%B3%E7%94%A8/UMOP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    百度开源UMOP解决特征层gt不匹配
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    踩坑记录
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            踩坑记录
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    专栏介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/%E5%9F%BA%E7%A1%80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/%E6%96%B0%E7%94%B5%E8%84%91%E9%85%8D%E7%8E%AF%E5%A2%83/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    windows配置深度学习环境
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/nano%E9%83%A8%E7%BD%B2yolov5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nano部署yolov5
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/LibtorchInWindows/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    windows下配置libtorch(vs/cmake)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/vscode%E9%85%8D%E7%BD%AEopencv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    windows+vscode配置opencv4.1.1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/ubuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    win11+ubuntu双系统的安装与卸载
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/WSL%E4%B8%8B%E9%85%8D%E7%BD%AEdocker%E7%8E%AF%E5%A2%83/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    WSL下GPU配置与docker安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/vscode%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%BC%80%E5%8F%91/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    vscode+devcontainer+docker容器开发
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/dockerlize%20GUI%20in%20wsl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    docker容器中图形化界面开发环境配置
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/ZeroTier%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    内网穿透
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    学习文档
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            学习文档
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    专栏介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/Algorithm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    算法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/DP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动态规划
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/Structure/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据结构
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/c%2B%2B11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    c++特性杂记
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/ToolDoc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    工具使用文档
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/PythonDoc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    python使用文档
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/CUDA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/LinearAlgebra/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性代数理论
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../Learning/Propagation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    波在介质中的传播学习笔记
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    地震反演
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            地震反演
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    专栏介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Basic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    反演概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    反演基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/BasicMath/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数学基础
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_5" >
        
          <label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    反射率法
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_5">
            <span class="md-nav__icon md-icon"></span>
            反射率法
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/RM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    概括
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/CoupleWave/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chapter2耦合波
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/Appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chapter4震源
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/ch5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chapter5反射与透射
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/ch6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chapter6递归求解反射系数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/Source/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chapter7层状半空间响应
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/Response/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    chapter7求解地震记录
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化方法笔记
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_7" >
        
          <label class="md-nav__link" for="__nav_6_7" id="__nav_6_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    论文笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_7">
            <span class="md-nav__icon md-icon"></span>
            论文笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/PaperNotes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    碎片
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/DTV/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DTV
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/Gan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    生成对抗网络
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Unet迁移学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../SeismicInversion/Paper/Review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Review
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CUDA
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            CUDA
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    专栏介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" checked>
        
          <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    《CUDA编程-基础与实战》笔记
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            《CUDA编程-基础与实战》笔记
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../c2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA中的线程组织
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../c3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA程序基本框架
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../c8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    共享内存的合理使用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../c9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    原子函数的合理使用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    线程束基本函数与协作组
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    线程束基本函数与协作组
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#simt-" class="md-nav__link">
    SIMT单指令-多线程执行模式
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#branch-divergence" class="md-nav__link">
    分支发散 branch divergence
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#independent-thread-scheduling" class="md-nav__link">
    独立线程调度 independent thread scheduling
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    线程束内基本函数
  </a>
  
    <nav class="md-nav" aria-label="线程束内基本函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#warp-vote-function" class="md-nav__link">
    线程表决函数warp vote function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    线程洗牌函数
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    归约计算
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    协作组
  </a>
  
    <nav class="md-nav" aria-label="协作组">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    归约计算
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    对归约函数进一步优化
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../c11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA流
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../Reduce/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reduce
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../Matrix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GEMM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../SoftMax/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SoftMax
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#simt-" class="md-nav__link">
    SIMT单指令-多线程执行模式
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#branch-divergence" class="md-nav__link">
    分支发散 branch divergence
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#independent-thread-scheduling" class="md-nav__link">
    独立线程调度 independent thread scheduling
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    线程束内基本函数
  </a>
  
    <nav class="md-nav" aria-label="线程束内基本函数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#warp-vote-function" class="md-nav__link">
    线程表决函数warp vote function
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    线程洗牌函数
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    归约计算
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    协作组
  </a>
  
    <nav class="md-nav" aria-label="协作组">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    归约计算
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    对归约函数进一步优化
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>线程束基本函数与协作组</h1>

<p>参考书目： <strong>CUDA编程基础与实践</strong></p>
<p>作者: 樊哲勇</p>
<p>章节： 第10章 线程束基本函数和协作组</p>
<h3 id="simt-">SIMT单指令-多线程执行模式<a class="headerlink" href="#simt-" title="Permanent link">&para;</a></h3>
<p>一个线程束中的多个线程执行相同的指令</p>
<h3 id="branch-divergence">分支发散 branch divergence<a class="headerlink" href="#branch-divergence" title="Permanent link">&para;</a></h3>
<p>一个线程束中的线程顺序执行判断语句的不同分支时会发生分支发散,只针对<strong>一个线程束</strong>中的线程</p>
<p>下面这段代码</p>
<div class="highlight"><pre><span></span><code><span class="k">if</span><span class="p">(</span><span class="n">condition</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">A</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">else</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">B</span>
<span class="p">}</span>
</code></pre></div>
<p>满足condition的线程会先执行A,其他线程会被闲置,执行完之后才轮到不满足condition的线程执行B,其他线程闲置,所以要尽量避免分支发散,但这不可避免,比如判断<code>tid&lt;N</code>,所以要先保证程序正确</p>
<h3 id="independent-thread-scheduling">独立线程调度 independent thread scheduling<a class="headerlink" href="#independent-thread-scheduling" title="Permanent link">&para;</a></h3>
<p>从伏特架构开始,引入了独立线程调度机制,每个线程有自己的程序计数器,使其线程间可以同步与通信,代价是增加了寄存器负担,单个线程的程序计数器需要两个寄存器,也就是说,这种独立线程调度机制使得SM种的每个线程可利用的寄存器少了两个,另外,独立线程调度机制没有假设线程束同步,也即是说你需要自己指定线程束同步,也就是比线程块同步函数<code>__syncthreads()</code>颗粒度更低的线程束同步函数<code>__syncwarp</code>,假如不想再伏特架构的GPU上使用独立线程调度机制,就需要在编译时指定虚拟架构低于伏特架构的计算能力,也就是</p>
<div class="highlight"><pre><span></span><code>-arch<span class="o">=</span>compute_60<span class="w"> </span>-code<span class="o">=</span>sm_70
</code></pre></div>
<p>在<strong>归约问题</strong>中,若所有线程位于一个线程束中,我们就可以使用<code>__syncwarp()</code>代替<code>__syncthreads()</code>,其原型为</p>
<div class="highlight"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="n">__syncwarp</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mh">0xfffffff</span><span class="p">)</span>
</code></pre></div>
<p>可选参数为掩码,其32个二进制数对应着线程束中32个线程,0/1为其对应的线程是否参与同步,默认全部参与, 所以归约核函数更改为</p>
<div class="highlight"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="n">__global__</span><span class="w"> </span><span class="nf">reduce_syncwarp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="o">*</span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="o">*</span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span>
<span class="w">    </span><span class="k">extern</span><span class="w"> </span><span class="n">__shared__</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="n">s_y</span><span class="p">[];</span>
<span class="w">    </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">d_x</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span><span class="c1">//否则容易s_y还没初始化好就开始累加了</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="c1">//如果计算的长度一半大于等于32</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">offset</span><span class="p">)</span><span class="c1">//只计算前面一半的线程</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">__syncthreads</span><span class="p">();</span><span class="c1">//否则容易到了下个循环,上个循环的线程还没计算完</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="c1">//计算长度的一半小于32,也就是16了,就可以看作一个线程束</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">offset</span><span class="p">)</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">__syncwarp</span><span class="p">();</span><span class="c1">//同步此线程束,而不用同步整个线程块</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>分析下面的情况</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">/</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">];</span>
<span class="w">    </span><span class="n">__syncwarp</span><span class="p">();</span><span class="c1">//同步此线程束</span>
<span class="p">}</span>
</code></pre></div>
<p><code>if (tid &lt; offset)</code>,制定了一些线程运行,其他线程限制,如果把此限制解除,就是所有线程一起运行,看起来减少了代码量,更加简洁,但是会引发<code>读写竞争</code>, 也就是比如这两个线程<code>s_y[0] += s_y[16]</code>和<code>s_y[16] += s_y[32]</code>,同时对<code>s_y[16]</code>,从而可能导致结果的错误,所以应该为</p>
<div class="highlight"><pre><span></span><code><span class="n">real</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="o">/</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">v</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">];</span>
<span class="w">    </span><span class="n">__syncwarp</span><span class="p">();</span><span class="c1">//同步此线程束(读取操作)</span>
<span class="w">    </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">];</span>
<span class="w">    </span><span class="n">__syncwarp</span><span class="p">();</span><span class="c1">//同步此线程束(写操作)</span>
<span class="p">}</span>
</code></pre></div>
<h3 id="_1">线程束内基本函数<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<h4 id="warp-vote-function">线程表决函数warp vote function<a class="headerlink" href="#warp-vote-function" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="kt">unsigned</span><span class="w"> </span><span class="nf">__ballot_sync</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">predicate</span><span class="p">);</span>
</code></pre></div>
<p>由旧掩码生成新掩码, 在参与计算(mask)的线程中,返回那些predicate为真(非零)的线程(新的mask)</p>
<div class="highlight"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="nf">__all_sync</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">predicate</span><span class="p">);</span>
</code></pre></div>
<p>在参与计算的线程中,predicate全为真,就返回1,否则返回0,也就是所有参选人都同意,才能返回1</p>
<p><div class="highlight"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="nf">__any_sync</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">predicate</span><span class="p">);</span>
</code></pre></div>
在参与计算的线程中,predicate只要有一个为真,就返回1,否则返回0,也就是所有参选人至少一人同意,就返回1</p>
<h4 id="_2">线程洗牌函数<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h4>
<p>这里提出了一个束内指标,通俗可以理解为在线程束内继续分块,由参数w控制,其只能取2,4,6,8,16,32,默认为32,也就是一个束内块中由w个线程</p>
<div class="highlight"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="n">lane_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">%</span><span class="n">w</span><span class="p">;</span>
</code></pre></div>
<p>由于w为2的幂次,可以用更高效的位运算(按位与)代替取模</p>
<div class="highlight"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="n">lane_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="o">&amp;</span><span class="p">(</span><span class="n">w</span><span class="mi">-1</span><span class="p">);</span>
</code></pre></div>
<p>假设线程块大小为16,假设w=8</p>
<div class="highlight"><pre><span></span><code>线程id:0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
束内id:0 1 2 3 4 5 6 7 0 1 2  3  4  5  6  7
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">T</span><span class="w"> </span><span class="n">__shfl_sync</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">srcLane</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpSize</span><span class="p">)</span>
</code></pre></div>
<p>返回束内块中束内指标为srcLane的v,这是一种广播机制</p>
<div class="highlight"><pre><span></span><code><span class="n">T</span><span class="w"> </span><span class="n">__shfl_up_sync</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpSize</span><span class="p">)</span>
</code></pre></div>
<p>束内块中,束内指标为t的返回t-d线程中的变量v,t-d&lt;0时,就返回其本身,也就是向上平移操作</p>
<div class="highlight"><pre><span></span><code><span class="n">T</span><span class="w"> </span><span class="n">__shfl_down_sync</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpSize</span><span class="p">)</span>
</code></pre></div>
<p>束内块中,束内指标为t的返回t+d线程中的变量v,t+d&gt;=w时,返回本身,就也就是向下平移操作</p>
<div class="highlight"><pre><span></span><code><span class="n">T</span><span class="w"> </span><span class="n">__shfl_xor_sync</span><span class="p">(</span><span class="kt">unsigned</span><span class="w"> </span><span class="n">mask</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="n">v</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">laneMask</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpSize</span><span class="p">)</span>
</code></pre></div>
<p>束内块中,束内指标为t的线程返回指标为t^laneMaske(t按位异或laneMask)线程的变量v,通俗将就是将threadIdx.x与threadIdx.x+laneMask线程之间互换数据.</p>
<p>以上函数均以<code>_sync</code>结尾,就代表了其都具有线程束同步功能,故不需要调用<code>__sync_warp</code></p>
<h3 id="_3">归约计算<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>使用线程洗牌函数对其进行归约</p>
<div class="highlight"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="n">__global__</span><span class="w"> </span><span class="nf">reduce_shfl</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="o">*</span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="o">*</span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span>
<span class="w">    </span><span class="k">extern</span><span class="w"> </span><span class="n">__shared__</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="n">s_y</span><span class="p">[];</span>
<span class="w">    </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">d_x</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">offset</span><span class="p">)</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">offset</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">real</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span><span class="c1">//下边省略的判断，所以要先把s_y[tid]读出来</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">y</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">__shfl_down_sync</span><span class="p">(</span><span class="n">FULL_MASK</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">offset</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p><code>__shfl_down_sync(FULL_MASK, y, offset)</code>表示了所有线程向上平移<code>offset</code>的线程对应的y值,也就等价于<code>y[tid + offset]</code></p>
<p>同样可以使用<code>__shfl_xor_sync()</code>完成同样的效果,<code>__shfl_xor_sync(FULL_MASK, y, offset)</code>返回值为该线程束内指标+offset的值,也就等价于<code>y[tid + offset]</code> 下面是例子offset=4时</p>
<div class="highlight"><pre><span></span><code>y:               0,1,2,3,4,5,6,7
__shfl_down_sync:4,5,6,7,4,5,6,7
__shfl_xor_sync: 4,5,6,7,0,1,2,3
</code></pre></div>
<p>这样做相比于之前的做法,不用显示的使用共享内存,而是__shfl_down_sync()将其赋值进了寄存器,速度也就更高效,同时去掉了同步函数,自动处理读写竞争问题</p>
<h3 id="_4">协作组<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>在有些并行算法中,需要若干线程间的协作,协作组可以为其提供灵活的协作方式,涉及到线程块内部协作,线程块之间协作,多设备之间协作,这里只讲解线程块内部写作</p>
<div class="highlight"><pre><span></span><code><span class="cp">#include</span><span class="cpf">&lt;cooperative_groups.h&gt;</span><span class="c1">//头文件</span>
<span class="k">using</span><span class="w"> </span><span class="k">namespace</span><span class="w"> </span><span class="nn">cooperative_groups</span><span class="p">;</span>
</code></pre></div>
<p>线程组<code>thread_group</code>的成员</p>
<ul>
<li><code>void sync()</code> 同步组内线程</li>
<li><code>unsigned size()</code>返回组内线程数</li>
<li><code>unsigned thread_rank()</code>返回当前线程在组内的标号</li>
<li><code>bool is_valid()</code>是否违反CUDA限制</li>
</ul>
<p>其中有成员变量<code>thread_block</code>,包含两个函数</p>
<ul>
<li><code>dim3 group_index()</code> 返回当前线程块索引,相当于<code>blockIdx.x</code></li>
<li><code>dim3 thread_index()</code> 返回当前线程索引,相当于<code>threadIdx.x</code></li>
</ul>
<div class="highlight"><pre><span></span><code><span class="n">thread_block</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">this_thread_block</span><span class="p">();</span>
<span class="n">g</span><span class="p">.</span><span class="n">sync</span><span class="p">();</span><span class="c1">//等价于__syncthreads()</span>
<span class="n">g</span><span class="p">.</span><span class="n">group_index</span><span class="p">();</span><span class="c1">//等价于blockIdx.x</span>
</code></pre></div>
<ul>
<li><code>tiled_partition()</code> 可以将一个线程块划分为若干片,每一片构成一个新的线程组,可以将片大小设置为2的幂次方且不超过32,与洗牌函数的w类似</li>
</ul>
<p>我们可以通过下面语句将一个线程块分割为线程束</p>
<div class="highlight"><pre><span></span><code><span class="n">thread_group</span><span class="w"> </span><span class="n">g32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tiled_partition</span><span class="p">(</span><span class="n">this_thread_block</span><span class="p">(),</span><span class="mi">32</span><span class="p">);</span>
<span class="c1">//将线程组更细分,一个组有4个线程</span>
<span class="n">thread_group</span><span class="w"> </span><span class="n">g4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tiled_partition</span><span class="p">(</span><span class="n">g32</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
<span class="c1">//在编译时就已知线程组大小可用模板化的版本</span>
<span class="n">thread_block_tile</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="w"> </span><span class="n">g32</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile_partition</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="p">(</span><span class="n">this_thread_block</span><span class="p">());</span>
</code></pre></div>
<p>这也叫做线程片,有和线程束内基本函数类似的表决和洗牌函数,但是不需要mask和w参数,默认全部参与计算</p>
<h4 id="_5">归约计算<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h4>
<p>利用协作组归约计算</p>
<div class="highlight"><pre><span></span><code><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s_y</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="n">thread_block_tile</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tiled_partition</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="p">(</span><span class="n">this_thread_block</span><span class="p">());</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">g</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="n">y</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">g</span><span class="p">.</span><span class="n">shfl_down</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">);</span>
<span class="p">}</span>
<span class="c1">// 类似线程束内函数的实现方式，这时线程束就是32</span>
<span class="c1">// for (int offset = 16; offset &gt; 0; offset &gt;&gt;= 1)</span>
<span class="c1">// {</span>
<span class="c1">//     y += __shfl_down_sync(FULL_MASK, y, offset);</span>
<span class="c1">// }</span>
</code></pre></div>
<h3 id="_6">对归约函数进一步优化<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p>我们之前的例子可以看出，我们只计算offset以内的线程，每经过一次循环，offset减半，参与计算的线程数也就减半，其余线程闲置，但是全局内存到共享内存线程利用率时100%，可以在归约之间加大计算比例，也就是不之间将全局内存复制到共享内存中，而是对其先进行一部分累加，共享内存存累加后的结果</p>
<p>为了做到这一点，一个线程要处理若干数据，要注意的时，一个线程处理的数据要尽可能间隔尽量远(一个线程块或一个网格)，因为相邻的数据要给相邻的线程计算，这样才能保证全局内存的合并访问</p>
<p>我们此时的例子并不满足GRID_SIZE = (N+BLOCK_SIZE-1)/BLOCK_SIZE, 也就是数据量大于网格中所有线程数</p>
<div class="highlight"><pre><span></span><code><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100000000</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">real</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">BLOCK_SIZE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">128</span><span class="p">;</span>
<span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">GRID_SIZE</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10240</span><span class="p">;</span><span class="c1">//在我们之前的例子中GRID_SIZE直接由(N+BLOCK_SIZE-1)/BLOCK_SIZE计算得到,也就是一个网格算完所有数据</span>
</code></pre></div>
<p>核函数为</p>
<div class="highlight"><pre><span></span><code><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">reduce1</span><span class="p">(</span><span class="n">real</span><span class="o">*</span><span class="w"> </span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">real</span><span class="o">*</span><span class="w"> </span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">)</span>
<span class="p">{</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="c1">//一个网格的所有线程作为步长</span>
<span class="w">    </span><span class="k">extern</span><span class="w"> </span><span class="n">__shared__</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="n">s</span><span class="p">[];</span>
<span class="w">    </span><span class="n">real</span><span class="w"> </span><span class="n">temp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bid</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">n</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span><span class="n">n</span><span class="o">+=</span><span class="n">stride</span><span class="p">)</span><span class="c1">//在复制之前先进行归约</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">temp</span><span class="o">+=</span><span class="n">d_x</span><span class="p">[</span><span class="n">n</span><span class="p">];</span><span class="c1">//由于在不同线程块,所以不需要同步</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">s</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="o">=</span><span class="n">temp</span><span class="p">;</span><span class="c1">//根据步长把所有数据归约到gridsize*blocksize长度的数组</span>
<span class="w">    </span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">&gt;&gt;</span><span class="mi">1</span><span class="p">;</span><span class="n">offset</span><span class="o">&gt;=</span><span class="mi">32</span><span class="p">;</span><span class="n">offset</span><span class="o">&gt;&gt;=</span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="p">(</span><span class="n">tid</span><span class="o">&lt;</span><span class="n">offset</span><span class="p">)</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="n">s</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="o">+=</span><span class="n">s</span><span class="p">[</span><span class="n">tid</span><span class="o">+</span><span class="n">offset</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">temp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span><span class="c1">//先把这个数读出来,防止读写竞争</span>
<span class="w">    </span><span class="n">thread_block_tile</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tiled_partition</span><span class="o">&lt;</span><span class="mi">32</span><span class="o">&gt;</span><span class="p">(</span><span class="n">this_thread_block</span><span class="p">());</span>
<span class="w">    </span><span class="c1">//等价于</span>
<span class="w">    </span><span class="c1">// thread_group g32 = tiled_partition(this_thread_block(),32);</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span><span class="w"> </span><span class="n">offset</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">;</span><span class="n">offset</span><span class="o">&gt;&gt;=</span><span class="mi">1</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">temp</span><span class="o">+=</span><span class="n">g</span><span class="p">.</span><span class="n">shfl_down</span><span class="p">(</span><span class="n">temp</span><span class="p">,</span><span class="n">offset</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span><span class="c1">//把gridsize*blocksize长度的数组归约到gridsize长度的数组</span>
<span class="w">    </span><span class="k">if</span><span class="p">(</span><span class="n">tid</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="n">d_y</span><span class="p">[</span><span class="n">bid</span><span class="p">]</span><span class="o">=</span><span class="n">temp</span><span class="p">;</span><span class="c1">//0号线程值就是归约和</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>之后调用两次核函数</p>
<div class="highlight"><pre><span></span><code><span class="c1">//把d_x归约到d_y,长度变化为N-&gt;GRID_SIZE*BLOCK_SIZE-&gt;GRID_SIZE</span>
<span class="n">reduce1</span><span class="o">&lt;&lt;&lt;</span><span class="n">GRID_SIZE</span><span class="p">,</span><span class="n">BLOCK_SIZE</span><span class="p">,</span><span class="n">smem</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_x</span><span class="p">,</span><span class="w"> </span><span class="n">d_y</span><span class="p">,</span><span class="n">N</span><span class="p">);</span>
<span class="c1">//把d_y归约到d_y,长度变化为GRID_SIZE-&gt;1024-&gt;1</span>
<span class="n">reduce1</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="mi">1024</span><span class="p">,</span><span class="k">sizeof</span><span class="p">(</span><span class="n">real</span><span class="p">)</span><span class="o">*</span><span class="mi">1024</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_y</span><span class="p">,</span><span class="w"> </span><span class="n">d_y</span><span class="p">,</span><span class="n">GRID_SIZE</span><span class="p">);</span>
</code></pre></div>
<p>但是当我们循环计算时会频繁动态开辟和释放内存,这占用了大量的时间,一种优化方案是通过静态内存的方式,其在编译时就分配好空间,不会再运行时反复分配,可以如下定义</p>
<div class="highlight"><pre><span></span><code><span class="n">__device__</span><span class="w"> </span><span class="n">real</span><span class="w"> </span><span class="n">static_y</span><span class="p">[</span><span class="n">GRID_SIZE</span><span class="p">];</span>
<span class="n">real</span><span class="o">*</span><span class="w"> </span><span class="n">d_y</span><span class="p">;</span>
<span class="n">CHECK</span><span class="p">(</span><span class="n">cudaGetSymbolAddress</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_y</span><span class="p">,</span><span class="n">static_y</span><span class="p">));</span>
</code></pre></div>


  




                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs"], "search": "../../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.dff1b7c8.min.js"></script>
      
        <script src="../../../js/tongji.js"></script>
      
        <script src="../../../js/google.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdnjs.loli.net/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>